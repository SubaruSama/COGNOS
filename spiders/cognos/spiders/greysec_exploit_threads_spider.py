import scrapy
from scrapy.spiders import CrawlSpider

class ForumContent(scrapy.Item):
    username = scrapy.Field()
    posts_quantity = scrapy.Field()
    date_joined = scrapy.Field()
    reputation = scrapy.Field()
    info_date_post = scrapy.Field()
    post_content = scrapy.Field()

class GreySecExploitDevSpider(CrawlSpider):
    name = 'grey_sec_exploit_dev_section'
    allowed_domains = ['greysec.net']
    start_urls = [
        'http://greysec.net/forumdisplay.php?fid=46'
    ]
    custom_settings = {
        'LOG_LEVEL': 'INFO'
    }
    forum_content = ForumContent()

    def start_requests(self):
        # TODO: seguir para a próxima página (procurar following links na documentação)
        yield scrapy.Request(url=self.start_urls[0], callback=self.extract_URL_from_forumdisplay)

    def extract_URL_from_forumdisplay(self, response):
        css_link_pattern = 'tr.inline_row:nth-child(n) > td:nth-child(n) > div:nth-child(n) > span:nth-child(n) > span a::attr(href)'
        paths = response.selector.css(css_link_pattern).getall()
        for path in paths:
            yield scrapy.Request(
                    url='https://{allowed_domains}/{path}'.format(allowed_domains=self.allowed_domains[0], 
                    path=path
                ), 
                    callback=self.parse
            )

    def parse(self, response):
        self.logger.info('----------- I\'am at the Page: %s -----------', response.url)
        self.logger.info('----------- Title: %s -----------', response.xpath('/html/head/title/text()').get())
        # Pegar todos os atributos que eh interessante (achar o CSS Selector ou XPATH correto) através de um selector genérico, 
        # colocar tudo dentro de um loop e a cada iteração vai adicionando no forum_content
        for username in response.selector.xpath('//*[@id="posts"]/div[*]/div[1]').getall():
            self.forum_content[username]['username'] = response.selector.xpath('//*[@id="posts"]/div[1]/div[1]/div[2]/strong/span/a/text()').get()

        for posts in response.selector.xpath('//*[@id="posts"]/div[*]/div[1]/div[3]/div[1]/i').getall():
            self.forum_content[posts]['posts_quantity'] = response.xpath('//*[@id="posts"]/div[1]/div[1]/div[3]/div[1]/i/text()').get()
        
        for date in response.selector.xpath('//*[@id="posts"]/div[*]/div[1]/div[3]/div[3]/i').getall():
            self.forum_content[date]['date_joined'] = response.xpath('//*[@id="posts"]/div[1]/div[1]/div[3]/div[3]/i/text()').get()

        for reputation in response.selector.xpath('//*[@id="posts"]/div[*]/div[1]/div[3]/div[4]/i/a/strong').getall():
            self.forum_content[reputation]['reputation'] = response.xpath('//*[@id="posts"]/div[1]/div[1]/div[3]/div[4]/i/a/strong/text()')

        for info_date_post in response.selector.xpath('//*[@id="posts"]/div[*]/div[2]/div[1]/span').getall():
            self.forum_content[info_date_post]['info_date_post'] = response.xpath('//*[@id="posts"]/div[1]/div[2]/div[1]/span/text()')
        
        for content in response.selector.xpath('//*[@id="posts"]/div[*]/div[2]/div[2]').getall():
            self.forum_content[content]['post_content'] = response.selector.xpath('//*[@id="posts"]/div[*]/div[2]/div[2]/text()').get()

        return self.forum_content
